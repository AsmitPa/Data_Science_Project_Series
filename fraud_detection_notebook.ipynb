
# Fraud Detection Using Classification Models

This notebook demonstrates how to build a fraud detection model using classification methods. It includes steps such as data cleaning, feature selection, hyperparameter tuning, and model evaluation.

## Step 1: Importing Libraries

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, roc_curve
from statsmodels.stats.outliers_influence import variance_inflation_factor
```

## Step 2: Load the Dataset

```python
# Load the dataset
data = pd.read_csv('fraud_data.csv')

# Display the first few rows
data.head()
```

## Step 3: Data Cleaning

### a. Handling Missing Values

```python
# Check for missing values
print(data.isnull().sum())

# Fill missing values with median (if any)
data.fillna(data.median(), inplace=True)
```

### b. Handling Outliers

```python
# Using IQR to detect and filter outliers in 'amount'
Q1 = data['amount'].quantile(0.25)
Q3 = data['amount'].quantile(0.75)
IQR = Q3 - Q1
data = data[~((data['amount'] < (Q1 - 1.5 * IQR)) | (data['amount'] > (Q3 + 1.5 * IQR)))]
```

### c. Handling Multi-Collinearity

```python
# Checking multicollinearity using Variance Inflation Factor (VIF)
X = data.drop(['isFraud', 'nameOrig', 'nameDest'], axis=1)
vif_data = pd.DataFrame()
vif_data['feature'] = X.columns
vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]
print(vif_data)
```

## Step 4: Train-Test Split

```python
# Define target and features
X = data.drop(['isFraud'], axis=1)
y = data['isFraud']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
```

## Step 5: Random Forest Model Training

```python
# Initialize the Random Forest Classifier
rf = RandomForestClassifier(random_state=42)

# Train the model
rf.fit(X_train, y_train)

# Predict on test data
y_pred = rf.predict(X_test)

# Evaluate the model
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:
", classification_report(y_test, y_pred))
```

## Step 6: Hyperparameter Tuning Using GridSearchCV

```python
# Define parameter grid
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, 30, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}

# GridSearchCV for Random Forest
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)

# Best parameters and model evaluation
best_rf = grid_search.best_estimator_
y_pred_best_rf = best_rf.predict(X_test)

print("Best Parameters: ", grid_search.best_params_)
print("Tuned Random Forest Accuracy:", accuracy_score(y_test, y_pred_best_rf))
print("Classification Report:
", classification_report(y_test, y_pred_best_rf))
```

## Step 7: Model Evaluation with ROC-AUC Curve

```python
# Predict probabilities
y_prob = best_rf.predict_proba(X_test)[:, 1]

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_prob)
roc_auc = roc_auc_score(y_test, y_prob)

plt.plot(fpr, tpr, label=f'Random Forest (AUC = {roc_auc:.2f})')
plt.title('ROC Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='lower right')
plt.show()
```

## Step 8: Conclusion

We successfully built a fraud detection model using Random Forest and tuned it with hyperparameters. The model's performance was evaluated using accuracy, classification report, and ROC-AUC score.
